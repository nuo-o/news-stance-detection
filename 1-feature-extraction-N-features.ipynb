{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd,gensim,collections,numpy as np,math,matplotlib.pyplot as plt,re, string,os\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "from collections import Counter\n",
    "from utils.dataset import DataSet\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import nltk, pickle\n",
    "%matplotlib inline\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    return \" \".join(re.findall(r'[\\w\\']+', s, flags=re.UNICODE)).lower()\n",
    "\n",
    "def tfidf_vectorization(train_stance, dict_articles):\n",
    "    # panda dataframe which has columns: 'Headline', 'Body ID', 'Stance'\n",
    "    bodyids =  train_stance[\"Body ID\"].values\n",
    "    bodies = [ dict_articles[bodyid] for bodyid in dict_articles.keys() ]\n",
    "    stances = train_stance[\"Stance\"].values\n",
    "\n",
    "    # tokenize each body\n",
    "    words_per_body = []\n",
    "    vocab_per_body = [] # for idf\n",
    "    for body in bodies:\n",
    "        words = word_tokenize(clean(body))\n",
    "        words = [w for w in words if w not in string.punctuation and w not in stopwords]\n",
    "        words_per_body.append(words)\n",
    "        vocab_per_body += list(set(words))\n",
    "    \n",
    "    # tokenize each headlline\n",
    "    headlines = train_stance[\"Headline\"].values\n",
    "    tokens_per_headline = []\n",
    "\n",
    "    for head in headlines:\n",
    "        words = word_tokenize(clean(head))\n",
    "        words = [w for w in words if w not in string.punctuation and w not in stopwords]\n",
    "        tokens_per_headline.append(words)\n",
    "\n",
    "    # compute idf, only needs words set\n",
    "    body_corpus_count = Counter(vocab_per_body)\n",
    "    idf = {}\n",
    "    \n",
    "    for vocab in body_corpus_count.keys():\n",
    "        D = len(dict_articles.keys())\n",
    "        idf[vocab] = math.log( D / body_corpus_count[vocab])\n",
    "        \n",
    "    # calculate body tfidf and save in dict(body id)-dict(word) \n",
    "    tfidf_body_dict = {}\n",
    "    \n",
    "    for i, bodyid in enumerate(dict_articles.keys()):\n",
    "        tf_body = Counter(words_per_body[i])\n",
    "        total_words_in_body = len(words_per_body[i])\n",
    "        \n",
    "        tfidf_per_word_dict = {}\n",
    "        for word in tf_body.keys():\n",
    "            tf = tf_body[word]/total_words_in_body\n",
    "            tfidf = tf * idf[word]\n",
    "            tfidf_per_word_dict[word] = tfidf\n",
    "            \n",
    "        tfidf_body_dict[bodyid] = tfidf_per_word_dict\n",
    "        \n",
    "    # compute headline tfidf and save in dict - dict\n",
    "    tfidf_headline_dict = {}\n",
    "    \n",
    "    for i,(head,bodyID) in enumerate(zip(headlines, bodyids)):\n",
    "        current_headline_tfidf_dict = {}\n",
    "        tokens = tokens_per_headline[i]\n",
    "        token_counts = Counter(tokens)\n",
    "        \n",
    "        for word in tokens:\n",
    "            if word in idf:\n",
    "                tfidf = token_counts[word]/len(tokens)*idf[word]\n",
    "                current_headline_tfidf_dict[word] = tfidf\n",
    "        tfidf_headline_dict[i] = current_headline_tfidf_dict\n",
    "        \n",
    "    return tfidf_headline_dict, tfidf_body_dict, tokens_per_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(headline_tfidf_dict, body_tfidf_dict, tokens_per_headline, bodyIDs):\n",
    "    feature_cosine, feature_dis, feature_kl, feature_word_overlap, feat_uncertain, feat_overlap_count = [],[], [], [], [],[]\n",
    "    \n",
    "    # loop through each headline \n",
    "    for i, bodyid in enumerate(bodyIDs):\n",
    "        headline_tokens = tokens_per_headline[i]\n",
    "        current_head_tfidf_dict = headline_tfidf_dict[i]\n",
    "        current_body_tfidf_dict = body_tfidf_dict[bodyid]\n",
    "        \n",
    "        # loop through each word\n",
    "        cosine = 0\n",
    "        distance = 0\n",
    "        kl = 0\n",
    "        n_word_overlap = len(list(set(current_head_tfidf_dict.keys()).intersection(current_body_tfidf_dict.keys())))\n",
    "        feat_overlap_count.append(n_word_overlap)\n",
    "        n_word_overlap = n_word_overlap/len(current_head_tfidf_dict.keys())\n",
    "        uncertain = len(list(set(current_head_tfidf_dict.keys()).intersection(set(uncertain_words))))\n",
    "        if uncertain >0:\n",
    "            uncertain = 1\n",
    "        \n",
    "        for word in headline_tokens:\n",
    "            if word in current_body_tfidf_dict:\n",
    "                vec1 = current_head_tfidf_dict[word]\n",
    "                vec2 = current_body_tfidf_dict[word]\n",
    "                cosine += vec1*vec2\n",
    "                distance += (vec1-vec2)**2\n",
    "                kl += vec1 * np.log(vec1 / vec2)\n",
    "                \n",
    "        # normalize vector dot        \n",
    "        norm_headline = np.linalg.norm(list(current_head_tfidf_dict.values()))\n",
    "        norm_body = np.linalg.norm(list(current_body_tfidf_dict.values()))\n",
    "        cosine = cosine / norm_headline / norm_body\n",
    "        feature_cosine.append(cosine)\n",
    "        \n",
    "        # square root distance\n",
    "        distance = math.sqrt(distance)\n",
    "        feature_dis.append(distance)\n",
    "        \n",
    "        # store other features\n",
    "        feature_kl.append(kl)\n",
    "        feature_word_overlap.append(n_word_overlap)\n",
    "        feat_uncertain.append(uncertain)\n",
    "        \n",
    "        \n",
    "    return feature_cosine, feature_dis, feature_kl, feature_word_overlap, feat_uncertain,feat_overlap_count\n",
    "\n",
    "uncertain_words = [\"report\", \"alleg\", \"possibl\", \"probabl\", \"may\", \"could\", \"can\", \"might\", \"suspect\", \"whether\", \"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_pipeline(train_stance, articles, file_save_path):\n",
    "        \n",
    "    headline_tfidf_dict, body_tfidf_dict, tokens_per_headline = tfidf_vectorization(train_stance, articles)\n",
    "    bodyids = train_stance['Body ID'].values\n",
    "    stances = train_stance['Stance'].values\n",
    "\n",
    "    cosine, dis, kl,overlap_ratio, uncertain, overlap_count = extract_features(headline_tfidf_dict, body_tfidf_dict, tokens_per_headline, bodyids)\n",
    "    \n",
    "    train_df = pd.DataFrame(np.column_stack([cosine, dis, kl,overlap_ratio, uncertain,overlap_count,stances]),\\\n",
    "                            columns=['cos','dis', 'kl', 'overlap_ratio', 'uncertain','overlap_count','Stance'])\n",
    "    train_df.to_csv(file_save_path)\n",
    "#     return cosine, dis, kl,overlap, uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n"
     ]
    }
   ],
   "source": [
    "# process train data\n",
    "train = DataSet('train')\n",
    "train_stance = pd.read_csv('fnc-1/train_stance_pd.csv')\n",
    "feature_extraction_pipeline( train_stance, train.articles, 'train_processed_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "test = DataSet('competition_test')\n",
    "# process test data\n",
    "test_stance = pd.read_csv('fnc-1/competition_test_stances.csv')\n",
    "feature_extraction_pipeline( test_stance, test.articles, 'test_processed_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold out data \n",
    "hold_out_stance = pd.read_csv('fnc-1/evaluate_stance_pd.csv')\n",
    "feature_extraction_pipeline( train_stance, train.articles, 'hold_out_processed_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证 feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stances = test_stance['Stance'].values\n",
    "# plt.figure()\n",
    "# plot_cos = []\n",
    "# feature = cos2\n",
    "# for (cos,stance) in zip(feature, stances):\n",
    "#     if stance != 'unrelated':\n",
    "#         plot_cos.append(cos)\n",
    "\n",
    "# for cos,stance in zip(feature, stances):\n",
    "#     if stance == 'unrelated':\n",
    "#         plot_cos.append(cos)\n",
    "\n",
    "# plt.plot(range(len(plot_cos)), plot_cos, 'g*')\n",
    "\n",
    "# plt.figure()\n",
    "# plot_cos = []\n",
    "# feature = cosine\n",
    "# stances = train_stance['Stance'].values\n",
    "# for cos,stance in zip(feature, stances):\n",
    "#     if stance != 'unrelated':\n",
    "#         plot_cos.append(cos)\n",
    "\n",
    "# for cos,stance in zip(feature, stances):\n",
    "#     if stance == 'unrelated':\n",
    "#         plot_cos.append(cos)\n",
    "\n",
    "# plt.plot(range(len(plot_cos)), plot_cos, 'g*')\n",
    "\n",
    "# plt.figure()\n",
    "# plot_cos = []\n",
    "# feature = kl\n",
    "# for cos,stance in zip(feature, stances):\n",
    "#     if stance != 'unrelated':\n",
    "#         plot_cos.append(cos)\n",
    "\n",
    "# for cos,stance in zip(feature, stances):\n",
    "#     if stance == 'unrelated':\n",
    "#         plot_cos.append(cos)\n",
    "\n",
    "# plt.plot(range(len(plot_cos)), plot_cos, 'g*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('say \"you are very beautiful\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
