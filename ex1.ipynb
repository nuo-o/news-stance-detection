{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from utils.dataset import DataSet\n",
    "import os\n",
    "import utils.generate_test_splits as split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n",
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "train = DataSet('train')\n",
    "test = DataSet('competition_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ex1: split the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_set_split(dataset, training = 0.9, base_dir=\"splits\"):\n",
    "    if not (os.path.exists(base_dir+ \"/\"+ \"training_ids.txt\")\n",
    "            and os.path.exists(base_dir+ \"/\"+ \"hold_out_ids.txt\")):\n",
    "        split.generate_hold_out_split(dataset,training,base_dir)\n",
    "\n",
    "    training_ids = split.read_ids(\"training_ids.txt\", base_dir)\n",
    "    hold_out_ids = split.read_ids(\"hold_out_ids.txt\", base_dir)\n",
    "\n",
    "    # get stances\n",
    "    stances_train = []\n",
    "    stances_hold_out = []\n",
    "    \n",
    "    for stance in dataset.stances:\n",
    "        if stance['Body ID'] in hold_out_ids:\n",
    "            stances_hold_out.append(stance)\n",
    "        else:\n",
    "            stances_train.append(stance)\n",
    "    \n",
    "    return stances_train, stances_hold_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_stance, hold_out_stance = training_set_split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_ratio(stance):\n",
    "    \n",
    "    agree = [ 1 for d in stance if d['Stance']== 'agree']\n",
    "    disagree = [ 1 for d in stance if d['Stance']== 'disagree']\n",
    "    discuss = [ 1 for d in stance if d['Stance']== 'discuss']\n",
    "    unrelated = [ 1 for d in stance if d['Stance']== 'unrelated']\n",
    "    \n",
    "    agree = sum(agree)\n",
    "    disagree = sum(disagree)\n",
    "    discuss = sum(discuss)\n",
    "    unrelated = sum(unrelated)\n",
    "    \n",
    "    if sum([agree, disagree, discuss, unrelated]) != len(stance):\n",
    "        print('Error, invalid calculation of elements in each class')\n",
    "    \n",
    "    total_num_stance = len(stance)\n",
    "    agree_ratio = round(agree/total_num_stance, 3)\n",
    "    disagree_ratio = round(disagree/total_num_stance, 3)\n",
    "    discuss_ratio = round(discuss/total_num_stance,3)\n",
    "    unrelated_ratio = round(unrelated/total_num_stance,3)\n",
    "    \n",
    "    return agree_ratio, disagree_ratio, discuss_ratio, unrelated_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agree,train_disagree, train_discus, train_unrelate = calculate_class_ratio(training_stance)\n",
    "hold_agree,hold_disagree, hold_discus, hold_unrelate = calculate_class_ratio(hold_out_stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ratio in training and hold-out dataset:\n",
      "\n",
      "\tTrain\tHold-out\n",
      "Agree\t 0.072 | 0.079\n",
      "Disagree 0.017 | 0.017\n",
      "Discuss\t 0.176 | 0.187\n",
      "Unrelate 0.735 | 0.717\n"
     ]
    }
   ],
   "source": [
    "# display class ratio in training and hold-out set\n",
    "print('Class ratio in training and hold-out dataset:\\n')\n",
    "print('\\tTrain\\tHold-out')\n",
    "print('Agree\\t', train_agree,'|', hold_agree)\n",
    "print('Disagree', train_disagree,'|', hold_disagree)\n",
    "print('Discuss\\t', train_discus, '|', hold_discus)\n",
    "print('Unrelate', train_unrelate, '|', hold_unrelate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('splitted_train_list_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(training_stance, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('splitted_evaluate_list_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(hold_out_stance, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('say \"your program has finished\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
